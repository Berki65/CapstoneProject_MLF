{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning Project",
   "id": "1dd3de7524db47a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " 1) data curation: how you choose the features (X) and the target (Y)\n",
    " 2) exploratory data analysis (including visualization and correlation matrix)\n",
    " 3) univariate results (and meta analysis)\n",
    " 4) multivariate results (and meta analysis)\n",
    " 5) benchmark linear/logistic regressions (including higher-order polynomials and/or interaction terms)\n",
    " 6) one machine learning algorithm (e.g., random forests or boosting)\n",
    " 7) k-fold cross-validation \n",
    " 8) performance evaluation (R-squared, AUROC, etc.)\n",
    " 9) key features (dimension reduction and feature selection techniques if necessary)\n",
    " 10) synthetic interpretation of results"
   ],
   "id": "281e58ad36f26581"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "421a67cf0a25738"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.169604Z",
     "start_time": "2024-11-29T11:33:55.167403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from prompt_toolkit.key_binding.bindings.named_commands import yank_last_arg\n",
    "from sklearn.linear_model import LinearRegression"
   ],
   "id": "e7345ac4c349ce36",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and clear up dataset",
   "id": "b8e12046d0bf064b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1) Load and edit the Dataset",
   "id": "f3e554f4986dbb29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.223090Z",
     "start_time": "2024-11-29T11:33:55.174747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "dataset_train = pd.read_csv(\"PM_train.csv\")\n",
    "dataset_test = pd.read_csv(\"PM_test.csv\")\n",
    "\n",
    "# Shift the cycle column forward by 1 to identify the last cycle before it resets\n",
    "dataset_train['Y'] = (dataset_train['cycle'] == dataset_train.groupby('id')['cycle'].transform('max')).astype(int)\n",
    "dataset_test['Y'] = (dataset_test['cycle'] == dataset_test.groupby('id')['cycle'].transform('max')).astype(int)\n",
    "\n",
    "# Define selected columns, including 'Y'\n",
    "selected_columns = ['id', 'cycle', 'setting1', 'setting2', 's2', 's3', 's4', 's6', 's7', 's8', 's9', 's11', 's12', 's13', 's14', 's15', 's17', 's20', 's21', 'Y']\n",
    "\n",
    "# Select the subset of data\n",
    "selected_dataset_train = dataset_train[selected_columns]\n",
    "selected_dataset_test = dataset_test[selected_columns]\n",
    "\n",
    "## Save the selected dataset to an Excel file\n",
    "# selected_dataset.to_excel(\"selected_dataset_with_Y.xlsx\", index=False)\n",
    "\n",
    "# Sort by 'id' and 'cycle' to ensure the data is in the correct order\n",
    "dataset_train = dataset_train.sort_values(['id', 'cycle'])\n",
    "dataset_test = dataset_test.sort_values(['id', 'cycle'])\n",
    "\n",
    "# Group by 'id' and select the last 10 cycles for each 'id'\n",
    "last_10_cycles_train = dataset_train.groupby('id').tail(10)\n",
    "last_10_cycles_test = dataset_test.groupby('id').tail(10)\n",
    "\n",
    "# Further filter the selected columns for this subset\n",
    "selected_last_10_cycles_train = last_10_cycles_train[selected_columns]\n",
    "selected_last_10_cycles_test = last_10_cycles_test[selected_columns]\n",
    "\n",
    "# Display the result\n",
    "selected_last_10_cycles_train.head()\n",
    "selected_last_10_cycles_test.head()\n",
    "\n",
    "# Define the features (X) and target (Y)\n",
    "X_train = selected_dataset_train # .drop(columns=['Y', 'id', 'cycle'])  # Drop 'Y', 'id', and 'cycle' if they are not part of the model\n",
    "Y_train = selected_dataset_train['Y']\n",
    "X_test = selected_dataset_test #.drop(columns=['Y', 'id', 'cycle'])  # Drop 'Y', 'id', and 'cycle' if they are not part of the model\n",
    "Y_test = selected_dataset_test['Y']\n",
    "\n",
    "# Alternatively, if using only the last 10 cycles:\n",
    "X_last_10_train = selected_last_10_cycles_train.drop(columns=['Y', 'id', 'cycle'])\n",
    "Y_last_10_train = selected_last_10_cycles_train['Y']\n",
    "X_last_10_test = selected_last_10_cycles_test.drop(columns=['Y', 'id', 'cycle'])\n",
    "Y_last_10_test = selected_last_10_cycles_test['Y']\n"
   ],
   "id": "f3fdc0d7b157bc90",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1) Visualization of the whole Dataset",
   "id": "4e9e1e485e4cff15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.280949Z",
     "start_time": "2024-11-29T11:33:55.278870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Visualization \n",
    "# selected_dataset_train.head()\n",
    "# selected_dataset_train.info()\n",
    "# \n",
    "# for column in selected_dataset_train.columns:\n",
    "#     if column not in ['id', 'Y']:  # Skip 'id' and 'Y' for this general visualization\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.title(f\"Distribution of {column}\")\n",
    "#         plt.plot(selected_dataset_train['cycle'], selected_dataset_train[column], alpha=0.7)\n",
    "#         plt.xlabel(\"Cycle\")\n",
    "#         plt.ylabel(column)\n",
    "#         plt.grid(True, alpha=0.5)\n",
    "#         plt.show()\n"
   ],
   "id": "d039a8b50c7b8c5f",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2) Visualization of the last 10 cycles",
   "id": "a8748228ffa8eea3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.336176Z",
     "start_time": "2024-11-29T11:33:55.334565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# selected_last_10_cycles_train.head()\n",
    "# selected_last_10_cycles_train.info()\n",
    "# \n",
    "# for column in selected_last_10_cycles_train.columns:\n",
    "#     if column not in ['id', 'Y']:  # Skip 'id' and 'Y' for this general visualization\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.title(f\"Distribution of {column}\")\n",
    "#         plt.plot(selected_last_10_cycles_train['cycle'], selected_last_10_cycles_train[column], alpha=0.7)\n",
    "#         plt.xlabel(\"Cycle\")\n",
    "#         plt.ylabel(column)\n",
    "#         plt.grid(True, alpha=0.5)\n",
    "#         plt.show()"
   ],
   "id": "87c96e24a1f91e01",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3) Scatter Plot Matrix",
   "id": "443f6e62111be658"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.391260Z",
     "start_time": "2024-11-29T11:33:55.389197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Heatmap\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# correlation_matrix = selected_last_10_cycles_train.corr()  # Compute the correlation matrix\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "# plt.title('Correlation Matrix Heatmap (Last 10 Cycles)')\n",
    "# plt.show()\n",
    "# \n",
    "# # Scatter plot matrix\n",
    "# numeric_columns = [col for col in selected_columns if col not in ['id', 'Y', 'cycle']]\n",
    "# sns.pairplot(selected_last_10_cycles_train, vars=numeric_columns[:20])  # Limit to first 6 for clarity\n",
    "# plt.suptitle('Scatter Plot Matrix (Last 10 Cycles)', y=1.02)\n",
    "# plt.show()\n",
    "# \n",
    "# # 3D Scatter Plot\n",
    "# fig = plt.figure(figsize=(10, 7))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     selected_last_10_cycles_train['setting1'],\n",
    "#     selected_last_10_cycles_train['s2'],\n",
    "#     selected_last_10_cycles_train['s3'],\n",
    "#     c='b', marker='o'\n",
    "# )\n",
    "# \n",
    "# # Label the axes\n",
    "# ax.set_xlabel('Setting 1')\n",
    "# ax.set_ylabel('S2')\n",
    "# ax.set_zlabel('S3')\n",
    "# plt.title('3D Scatter Plot (Last 10 Cycles)')\n",
    "# plt.show()"
   ],
   "id": "1af116a0148278c0",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Regression",
   "id": "fa1dcc68789bc81e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.513931Z",
     "start_time": "2024-11-29T11:33:55.446053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit the regression model\n",
    "model = LinearRegression()\n",
    "# model.fit(X_train, Y_train)\n",
    "model.fit(X_last_10_train, Y_last_10_train)\n",
    "\n",
    "# Define the threshold for binary classification\n",
    "threshold = 2\n",
    "\n",
    "# Predict using the regression model\n",
    "y_pred = model.predict(X_last_10_test)\n",
    "\n",
    "# Convert regression outputs and true labels to binary\n",
    "y_test_binary = selected_last_10_cycles_test['Y']\n",
    "y_pred_binary = (y_pred <= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test_binary, y_pred_binary))"
   ],
   "id": "e10320cbbe9288",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       828\n",
      "           1       0.10      1.00      0.18        92\n",
      "\n",
      "    accuracy                           0.10       920\n",
      "   macro avg       0.05      0.50      0.09       920\n",
      "weighted avg       0.01      0.10      0.02       920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.608606Z",
     "start_time": "2024-11-29T11:33:55.604976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_columns = [col for col in selected_columns if col not in ['id', 'cycle', 'Y']]\n",
    "# \n",
    "# # Create scatter plots with regression lines\n",
    "# for column in x_columns:\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     sns.regplot(x=selected_last_10_cycles[column], y=selected_last_10_cycles['Y'], scatter_kws={'s': 10}, line_kws={'color': 'red'})\n",
    "#     plt.title(f'Regression of Y on {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Y')\n",
    "#     plt.show()"
   ],
   "id": "1074f5c2f2db0662",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "fdfd919f873e5413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.809325Z",
     "start_time": "2024-11-29T11:33:55.705579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_data = selected_dataset_train\n",
    "# Step 1: Create target labels indicating engine swap (1: needs swapping, 0: does not need swapping)\n",
    "threshold = 5  # Define the threshold for remaining cycles\n",
    "train_data['RUL'] = train_data.groupby('id')['cycle'].transform(max) - train_data['cycle']\n",
    "train_data['Y'] = (train_data['RUL'] <= threshold).astype(int)\n",
    "\n",
    "# Step 2: Define features (X) and target (Y)\n",
    "features = train_data.columns.difference(['id', 'cycle', 'RUL', 'Y'])\n",
    "X = train_data[features]\n",
    "y = train_data['Y']\n",
    "\n",
    "# Step 4: Random Forest Classifier with Cross-Validation\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Performance Metrics\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print results\n",
    "print(\"Classification Report:\\n\", classification_report_result)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "print(\"Mean Cross-Validation AUC:\", cv_scores.mean())\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract TP, FP, FN, TN from the confusion matrix\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# Print the results\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "\n",
    "# Optionally, display the confusion matrix for better visualization\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ],
   "id": "922e7c5bcbb8ce4b",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20631, 16504]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[133], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Step 4: Random Forest Classifier with Cross-Validation\u001B[39;00m\n\u001B[1;32m     18\u001B[0m rf \u001B[38;5;241m=\u001B[39m RandomForestClassifier(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[0;32m---> 19\u001B[0m cv_scores \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mroc_auc\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Fit the model\u001B[39;00m\n\u001B[1;32m     22\u001B[0m rf\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:562\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    560\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 562\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    563\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    564\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    567\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    569\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    571\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    574\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    209\u001B[0m         )\n\u001B[1;32m    210\u001B[0m     ):\n\u001B[0;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    221\u001B[0m     )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:290\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m     56\u001B[0m     {\n\u001B[1;32m     57\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m\"\u001B[39m: [HasMethods(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m)],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     96\u001B[0m     error_score\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mnan,\n\u001B[1;32m     97\u001B[0m ):\n\u001B[1;32m     98\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \n\u001B[1;32m    100\u001B[0m \u001B[38;5;124;03m    Read more in the :ref:`User Guide <multimetric_cross_validation>`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;124;03m    [0.28009951 0.3908844  0.22784907]\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 290\u001B[0m     X, y, groups \u001B[38;5;241m=\u001B[39m \u001B[43mindexable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    292\u001B[0m     cv \u001B[38;5;241m=\u001B[39m check_cv(cv, y, classifier\u001B[38;5;241m=\u001B[39mis_classifier(estimator))\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(scoring):\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/utils/validation.py:455\u001B[0m, in \u001B[0;36mindexable\u001B[0;34m(*iterables)\u001B[0m\n\u001B[1;32m    436\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001B[39;00m\n\u001B[1;32m    437\u001B[0m \n\u001B[1;32m    438\u001B[0m \u001B[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    454\u001B[0m result \u001B[38;5;241m=\u001B[39m [_make_indexable(X) \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m iterables]\n\u001B[0;32m--> 455\u001B[0m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/utils/validation.py:409\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    407\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 409\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    410\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    411\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[1;32m    412\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [20631, 16504]"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Neural Networks",
   "id": "4a533d3e6d2ea2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:33:55.873322Z",
     "start_time": "2024-11-29T08:24:40.445075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Step 1: Scale the Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Build the Neural Network\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
    "    Dropout(0.3),  # Add dropout for regularization\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 3: Train the Model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "y_pred_proba_nn = model.predict(X_test_scaled)\n",
    "y_pred_nn = (y_pred_proba_nn > 0.5).astype(int)\n",
    "\n",
    "# Performance Metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nn))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba_nn))"
   ],
   "id": "a14d8611532717bc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

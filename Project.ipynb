{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning Project",
   "id": "1dd3de7524db47a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " 1) data curation: how you choose the features (X) and the target (Y)\n",
    " 2) exploratory data analysis (including visualization and correlation matrix)\n",
    " 3) univariate results (and meta analysis)\n",
    " 4) multivariate results (and meta analysis)\n",
    " 5) benchmark linear/logistic regressions (including higher-order polynomials and/or interaction terms)\n",
    " 6) one machine learning algorithm (e.g., random forests or boosting)\n",
    " 7) k-fold cross-validation \n",
    " 8) performance evaluation (R-squared, AUROC, etc.)\n",
    " 9) key features (dimension reduction and feature selection techniques if necessary)\n",
    " 10) synthetic interpretation of results"
   ],
   "id": "281e58ad36f26581"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Introduction",
   "id": "95740ad3c8b8eccb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For my Project I choose a **Airplane Engine Dataset** which has **27** columns and **20631** entries for the train dataset the test dataset contains **11939** entries. \n",
    "The dataset contains the following columns:\n",
    "- id: Engine ID, \n",
    "- cycle: Cycle number,\n",
    "- setting1-3: Engine setting 1-3,\n",
    "- s1-s21: Sensor measurements s1-s21,\n",
    "- Y: Binary target label indicating engine swap (1: needs swapping, 0: does not need swapping)."
   ],
   "id": "297860e5985a0ba1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "421a67cf0a25738"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.029334Z",
     "start_time": "2024-12-03T01:57:15.978986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from prompt_toolkit.key_binding.bindings.named_commands import yank_last_arg\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from main import Y_last_10_train"
   ],
   "id": "e7345ac4c349ce36",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and clear up dataset",
   "id": "b8e12046d0bf064b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1) Load and edit the Dataset",
   "id": "f3e554f4986dbb29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.070884Z",
     "start_time": "2024-12-03T01:57:16.032729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "dataset_train = pd.read_csv(\"PM_train.csv\")\n",
    "dataset_test = pd.read_csv(\"PM_test.csv\")\n",
    "\n",
    "# Shift the cycle column forward by 1 to identify the last cycle before it resets\n",
    "dataset_train['Y'] = (dataset_train['cycle'] == dataset_train.groupby('id')['cycle'].transform('max')).astype(int)\n",
    "dataset_test['Y'] = (dataset_test['cycle'] == dataset_test.groupby('id')['cycle'].transform('max')).astype(int)\n",
    "\n",
    "# Define selected columns, including 'Y'\n",
    "selected_columns = ['id', 'cycle', 'setting1', 'setting2', 's2', 's3', 's4', 's6', 's7', 's8', 's9', 's11', 's12', 's13', 's14', 's15', 's17', 's20', 's21', 'Y']\n",
    "\n",
    "# Select the subset of data\n",
    "selected_dataset_train = dataset_train[selected_columns]\n",
    "selected_dataset_test = dataset_test[selected_columns]\n",
    "\n",
    "# Sort by 'id' and 'cycle' to ensure the data is in the correct order\n",
    "dataset_train = dataset_train.sort_values(['id', 'cycle'])\n",
    "dataset_test = dataset_test.sort_values(['id', 'cycle'])\n",
    "\n",
    "# Group by 'id' and select the last 10 cycles for each 'id'\n",
    "last_10_cycles_train = dataset_train.groupby('id').tail(10)\n",
    "last_10_cycles_test = dataset_test.groupby('id').tail(10)\n",
    "# Further filter the selected columns for this subset\n",
    "selected_last_10_cycles_train = last_10_cycles_train[selected_columns]\n",
    "selected_last_10_cycles_test = last_10_cycles_test[selected_columns]\n",
    "\n",
    "# Display the result\n",
    "selected_last_10_cycles_train.head()\n",
    "selected_last_10_cycles_test.head()\n",
    "\n",
    "# Define the features (X) and target (Y)\n",
    "X_train = selected_dataset_train.drop(columns=['Y', 'id', 'cycle'])  # Drop 'Y', 'id', and 'cycle' if they are not part of the model\n",
    "Y_train = selected_dataset_train['Y']\n",
    "X_test = selected_dataset_test.drop(columns=['Y', 'id', 'cycle'])  # Drop 'Y', 'id', and 'cycle' if they are not part of the model\n",
    "Y_test = selected_dataset_test['Y']\n",
    "\n",
    "# Alternatively, if using only the last 10 cycles:\n",
    "X_last_10_train = selected_last_10_cycles_train.drop(columns=['Y', 'id', 'cycle'])\n",
    "Y_last_10_train = selected_last_10_cycles_train['Y']\n",
    "X_last_10_test = selected_last_10_cycles_test.drop(columns=['Y', 'id', 'cycle'])\n",
    "Y_last_10_test = selected_last_10_cycles_test['Y']\n"
   ],
   "id": "f3fdc0d7b157bc90",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "After visualizing the dataset, I decided to use the following columns as features:\n",
    "- id: Engine ID,\n",
    "- cycle: Cycle number,\n",
    "- setting1: Engine setting 1,\n",
    "- setting2: Engine setting 2,\n",
    "- s2: Sensor measurement 2,\n",
    "- s3: Sensor measurement 3,\n",
    "- s4: Sensor measurement 4,\n",
    "- s6: Sensor measurement 6,\n",
    "- s7: Sensor measurement 7,\n",
    "- s8: Sensor measurement 8,\n",
    "- s9: Sensor measurement 9,\n",
    "- s11: Sensor measurement 11,\n",
    "- s12: Sensor measurement 12,\n",
    "- s13: Sensor measurement 13,\n",
    "- s14: Sensor measurement 14,\n",
    "- s15: Sensor measurement 15,\n",
    "- s17: Sensor measurement 17,\n",
    "- s20: Sensor measurement 20,\n",
    "- s21: Sensor measurement 21,\n",
    "- Y: Binary target label indicating engine swap (1: needs swapping, 0: does not need swapping). Which I created on my own by using the last value before the id goes up by one.   \n",
    "\n",
    "The reason for this is that these values are the most relevant for the prediction of the target label 'Y' because the other columns are null values and don't change.\n",
    " "
   ],
   "id": "f5f471170f5a4237"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1) Visualization of the whole Dataset",
   "id": "4e9e1e485e4cff15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.111566Z",
     "start_time": "2024-12-03T01:57:16.110026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Visualization \n",
    "# selected_dataset_train.head()\n",
    "# selected_dataset_train.info()\n",
    "# \n",
    "# for column in selected_dataset_train.columns:\n",
    "#     if column not in ['id', 'Y']:  # Skip 'id' and 'Y' for this general visualization\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.title(f\"Distribution of {column}\")\n",
    "#         plt.plot(selected_dataset_train['cycle'], selected_dataset_train[column], alpha=0.7)\n",
    "#         plt.xlabel(\"Cycle\")\n",
    "#         plt.ylabel(column)\n",
    "#         plt.grid(True, alpha=0.5)\n",
    "#         plt.show()\n"
   ],
   "id": "d039a8b50c7b8c5f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I this part I visualized the whole dataset and the distribution of the columns in the dataset. To get a rough view about the dataset.",
   "id": "de5c5c2eb783a26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2) Visualization of the last 10 cycles",
   "id": "a8748228ffa8eea3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.148319Z",
     "start_time": "2024-12-03T01:57:16.146712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# selected_last_10_cycles_train.head()\n",
    "# selected_last_10_cycles_train.info()\n",
    "# \n",
    "# for column in selected_last_10_cycles_train.columns:\n",
    "#     if column not in ['id', 'Y']:  # Skip 'id' and 'Y' for this general visualization\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.title(f\"Distribution of {column}\")\n",
    "#         plt.plot(selected_last_10_cycles_train['cycle'], selected_last_10_cycles_train[column], alpha=0.7)\n",
    "#         plt.xlabel(\"Cycle\")\n",
    "#         plt.ylabel(column)\n",
    "#         plt.grid(True, alpha=0.5)\n",
    "#         plt.show()"
   ],
   "id": "87c96e24a1f91e01",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I this part I visualized the last 10 cycles of the dataset and the distribution of the columns in the dataset. To get a more narrow insight about the dataset.",
   "id": "97fbd53667d30291"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3) Scatter Plot Matrix",
   "id": "443f6e62111be658"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.185246Z",
     "start_time": "2024-12-03T01:57:16.183588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Heatmap\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# correlation_matrix = selected_last_10_cycles_train.corr()  # Compute the correlation matrix\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "# plt.title('Correlation Matrix Heatmap (Last 10 Cycles)')\n",
    "# plt.show()\n",
    "# \n",
    "# # Scatter plot matrix\n",
    "# numeric_columns = [col for col in selected_columns if col not in ['id', 'Y', 'cycle']]\n",
    "# sns.pairplot(selected_last_10_cycles_train, vars=numeric_columns[:20])  # Limit to first 6 for clarity\n",
    "# plt.suptitle('Scatter Plot Matrix (Last 10 Cycles)', y=1.02)\n",
    "# plt.show()\n",
    "# \n",
    "# # 3D Scatter Plot\n",
    "# fig = plt.figure(figsize=(10, 7))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     selected_last_10_cycles_train['setting1'],\n",
    "#     selected_last_10_cycles_train['s2'],\n",
    "#     selected_last_10_cycles_train['s3'],\n",
    "#     c='b', marker='o'\n",
    "# )\n",
    "# \n",
    "# # Label the axes\n",
    "# ax.set_xlabel('Setting 1')\n",
    "# ax.set_ylabel('S2')\n",
    "# ax.set_zlabel('S3')\n",
    "# plt.title('3D Scatter Plot (Last 10 Cycles)')\n",
    "# plt.show()"
   ],
   "id": "1af116a0148278c0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Correlation Matrix and Scatter Plot Matrix are used to visualize the correlation between the columns and the distribution of the columns in the dataset.\n",
    "This process helped a lot to find the sweets-pot for the number of cycles I use before the engine gets swapped."
   ],
   "id": "9f45cde7dc4ed4b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4) Logistic Regression",
   "id": "fa1dcc68789bc81e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:33:26.777737Z",
     "start_time": "2024-12-03T02:33:26.751399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logistic Regression Example\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the dataset is available as `data`\n",
    "# Step 1: Define features and target\n",
    "# Replace 'features' and 'target' with actual column names or data\n",
    "# features = data.drop(columns=['target_column'])\n",
    "# target = data['target_column']\n",
    "\n",
    "# Temporary example (remove/comment after replacing with actual data)\n",
    "# features, target = X, y\n",
    "\n",
    "# Step 2: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Initialize and Train Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predict and Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Accuracy and Classification Report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# AUROC Score\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Logistic Regression (AUROC = {auroc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "a7401b6dd972db4f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 17\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Assuming the dataset is available as `data`\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Step 1: Define features and target\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Replace 'features' and 'target' with actual column names or data\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Step 2: Train-Test Split\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(\u001B[43mfeatures\u001B[49m, target, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Step 3: Initialize and Train Logistic Regression Model\u001B[39;00m\n\u001B[1;32m     20\u001B[0m model \u001B[38;5;241m=\u001B[39m LogisticRegression(max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'features' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.466039Z",
     "start_time": "2024-12-03T01:57:16.418559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # from sklearn.metrics import accuracy_score, classification_report, r2_score\n",
    "# # from sklearn.linear_model import LinearRegression\n",
    "# # \n",
    "# # # Fit the regression model\n",
    "# # model = LinearRegression()\n",
    "# # # model.fit(X_train, Y_train)\n",
    "# # model.fit(X_last_10_train, Y_last_10_train)\n",
    "# # \n",
    "# # # Define the threshold for binary classification\n",
    "# # threshold = 1\n",
    "# # \n",
    "# # # Predict using the regression model\n",
    "# # y_pred = model.predict(X_last_10_test)\n",
    "# # \n",
    "# # print(y_pred.min(), y_pred.max())\n",
    "# # \n",
    "# # # Convert regression outputs and true labels to binary\n",
    "# # y_test_binary = selected_last_10_cycles_test['Y']\n",
    "# # y_pred_binary = (y_pred <= threshold).astype(int)\n",
    "# # \n",
    "# # # Evaluate the model\n",
    "# # accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "# # \n",
    "# # print(f'Accuracy: {accuracy}')\n",
    "# # print(classification_report(y_test_binary, y_pred_binary))\n",
    "# # print(f'R^2 {r2_score(y_test_binary, y_pred_binary)}')\n",
    "# \n",
    "# from sklearn.metrics import accuracy_score, classification_report, r2_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# \n",
    "# # Fit the logistic regression model\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_last_10_train, Y_last_10_train)\n",
    "# \n",
    "# # Predict using the logistic regression model\n",
    "# y_pred_proba = model.predict_proba(X_last_10_test)[:, 1]  # Get probability for the positive class\n",
    "# \n",
    "# # Define the threshold for binary classification\n",
    "# threshold = 0.5\n",
    "# \n",
    "# # Convert probabilities to binary predictions\n",
    "# y_pred_binary = (y_pred_proba >= threshold).astype(int)\n",
    "# \n",
    "# # True labels for evaluation\n",
    "# y_test_binary = selected_last_10_cycles_test['Y']\n",
    "# \n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "# \n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# print(classification_report(y_test_binary, y_pred_binary))\n",
    "# print(f'R^2 {r2_score(y_test_binary, y_pred_binary)}')\n",
    "# \n",
    "# from sklearn.metrics import accuracy_score, classification_report, r2_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# import numpy as np\n",
    "# \n",
    "# # Scale the data\n",
    "# scaler = StandardScaler()\n",
    "# X_last_10_train_scaled = scaler.fit_transform(X_last_10_train)\n",
    "# X_last_10_test_scaled = scaler.transform(X_last_10_test)\n",
    "# \n",
    "# # Compute class weights to handle imbalance\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(Y_last_10_train), y=Y_last_10_train)\n",
    "# class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "# \n",
    "# # Fit the logistic regression model with increased iterations and class weights\n",
    "# model = LogisticRegression(max_iter=500, class_weight=class_weight_dict)\n",
    "# model.fit(X_last_10_train_scaled, Y_last_10_train)\n",
    "# \n",
    "# # Predict probabilities for the positive class\n",
    "# y_pred_proba = model.predict_proba(X_last_10_test_scaled)[:, 1]\n",
    "# \n",
    "# # Define the threshold for binary classification\n",
    "# threshold = 0.5\n",
    "# y_pred_binary = (y_pred_proba >= threshold).astype(int)\n",
    "# \n",
    "# # True labels for evaluation\n",
    "# y_test_binary = selected_last_10_cycles_test['Y']\n",
    "# \n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# print(classification_report(y_test_binary, y_pred_binary, zero_division=1))\n",
    "# print(f'R^2: {r2_score(y_test_binary, y_pred_binary)}')\n",
    "# \n",
    "# \n",
    "# from sklearn.metrics import roc_auc_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# # Predict probabilities for the positive class\n",
    "# y_pred_proba = model.predict_proba(X_last_10_test_scaled)[:, 1]\n",
    "# \n",
    "# # Calculate AUROC\n",
    "# auroc = roc_auc_score(y_test_binary, y_pred_proba)\n",
    "# print(f'AUROC: {auroc}')\n",
    "# \n",
    "# # Plot ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_proba)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f'Logistic Regression (AUROC = {auroc:.2f})')\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()\n"
   ],
   "id": "e10320cbbe9288",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1) Random Forest",
   "id": "fdfd919f873e5413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.546546Z",
     "start_time": "2024-12-03T01:57:16.542372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve\n",
    "# \n",
    "# # Step 1: Create target labels indicating engine swap (1: needs swapping, 0: does not need swapping)\n",
    "# train_data = dataset_train.copy()\n",
    "# threshold = 10  # Define the threshold for remaining cycles\n",
    "# train_data['RUL'] = train_data.groupby('id')['cycle'].transform(max) - train_data['cycle']\n",
    "# train_data['Y'] = (train_data['RUL'] <= threshold).astype(int)\n",
    "# \n",
    "# # Step 2: Define features (X) and target (Y)\n",
    "# features = train_data.columns.difference(['id', 'cycle', 'RUL', 'Y'])\n",
    "# X = train_data[features]\n",
    "# y = train_data['Y']\n",
    "# \n",
    "# # Step 3: Train-Test Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Step 4: Random Forest Classifier with Cross-Validation\n",
    "# rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "# cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "# \n",
    "# # Fit the model\n",
    "# rf.fit(X_train, y_train)\n",
    "# \n",
    "# # Evaluate the model on the test set\n",
    "# y_pred = rf.predict(X_test)\n",
    "# y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "# \n",
    "# # Performance Metrics\n",
    "# classification_report_result = classification_report(y_test, y_pred)\n",
    "# roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "# \n",
    "# # Print results\n",
    "# print(\"Classification Report:\\n\", classification_report_result)\n",
    "# print(\"ROC-AUC Score:\", roc_auc)\n",
    "# print(\"Mean Cross-Validation AUC:\", cv_scores.mean())\n",
    "# \n",
    "# # Generate the confusion matrix\n",
    "# conf_matrix_rf = confusion_matrix(y_test, y_pred)\n",
    "# \n",
    "# # Extract TP, FP, FN, TN from the confusion matrix\n",
    "# TN_nn, FP_nn, FN_nn, TP_nn = conf_matrix_rf.ravel()\n",
    "# \n",
    "# # Print the TP/FP breakdown\n",
    "# print(f\"True Positives (TP): {TP_nn}\")\n",
    "# print(f\"False Positives (FP): {FP_nn}\")\n",
    "# print(f\"True Negatives (TN): {TN_nn}\")\n",
    "# print(f\"False Negatives (FN): {FN_nn}\")\n",
    "# \n",
    "# # Optionally, display the confusion matrix\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(conf_matrix_rf)\n",
    "# \n",
    "# auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "# print(f\"\\nAUROC: {auroc}\")\n",
    "# \n",
    "# # Plot the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f\"AUROC = {auroc:.2f}\")\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ],
   "id": "fcbfed6979fadeb5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.594287Z",
     "start_time": "2024-12-03T01:57:16.592116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve\n",
    "# \n",
    "# \n",
    "# \n",
    "# rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "# cv_scores = cross_val_score(rf, X_last_10_train, Y_last_10_train, cv=5, scoring='roc_auc')\n",
    "# \n",
    "# rf.fit(X_last_10_train, Y_last_10_train)\n",
    "# \n",
    "# y_pred = rf.predict(X_last_10_test)\n",
    "# y_pred_proba = rf.predict_proba(X_last_10_test)[:, 1]\n",
    "# \n",
    "# # Performance Metrics\n",
    "# classification_report_result = classification_report(Y_last_10_test, y_pred)\n",
    "# roc_auc = roc_auc_score(Y_last_10_test, y_pred_proba)\n",
    "# \n",
    "# # Print results\n",
    "# print(\"Classification Report:\\n\", classification_report_result)\n",
    "# print(\"ROC-AUC Score:\", roc_auc)\n",
    "# print(\"Mean Cross-Validation AUC:\", cv_scores.mean())\n",
    "# \n",
    "# # Generate the confusion matrix\n",
    "# conf_matrix_rf = confusion_matrix(Y_last_10_test, y_pred)\n",
    "# \n",
    "# # Extract TP, FP, FN, TN from the confusion matrix\n",
    "# TN_nn, FP_nn, FN_nn, TP_nn = conf_matrix_rf.ravel()\n",
    "# \n",
    "# # Print the TP/FP breakdown\n",
    "# print(f\"True Positives (TP): {TP_nn}\")\n",
    "# print(f\"False Positives (FP): {FP_nn}\")\n",
    "# print(f\"True Negatives (TN): {TN_nn}\")\n",
    "# print(f\"False Negatives (FN): {FN_nn}\")\n",
    "# \n",
    "# # Optionally, display the confusion matrix\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(conf_matrix_rf)\n",
    "# \n",
    "# auroc = roc_auc_score(Y_last_10_test, y_pred_proba)\n",
    "# print(f\"\\nAUROC: {auroc}\")\n",
    "# \n",
    "# # Plot the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(Y_last_10_train, y_pred_proba)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f\"AUROC = {auroc:.2f}\")\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "# \n"
   ],
   "id": "17f21434b599cae8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.634972Z",
     "start_time": "2024-12-03T01:57:16.632837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve\n",
    "# \n",
    "# # Step 1: Create target labels indicating engine swap (1: needs swapping, 0: does not need swapping)\n",
    "# threshold = 10  # Define the threshold for remaining cycles\n",
    "# \n",
    "# # train_data = dataset_train.copy()\n",
    "# # train_data['RUL'] = train_data.groupby('id')['cycle'].transform(max) - train_data['cycle']\n",
    "# # train_data['Y'] = (train_data['RUL'] <= threshold).astype(int)\n",
    "# \n",
    "# # Step 2: Define features (X) and target (Y)\n",
    "# # features = train_data.columns.difference(['id',  'cycle', 'RUL', 'Y'])\n",
    "# # X = train_data[features]\n",
    "# # y = train_data['Y']\n",
    "# \n",
    "# # Step 3: Train-Test Split\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Step 4: Random Forest Classifier with Cross-Validation\n",
    "# rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "# cv_scores = cross_val_score(rf, X_train, Y_train, cv=5, scoring='roc_auc')\n",
    "# \n",
    "# # Fit the model\n",
    "# rf.fit(X_train, Y_train)\n",
    "# \n",
    "# # Evaluate the model on the test set\n",
    "# y_pred = rf.predict(X_test)\n",
    "# y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "# \n",
    "# # Performance Metrics\n",
    "# classification_report_result = classification_report(Y_test, y_pred)\n",
    "# roc_auc = roc_auc_score(Y_test, y_pred_proba)\n",
    "# \n",
    "# # Print results\n",
    "# print(\"Classification Report:\\n\", classification_report_result)\n",
    "# print(\"ROC-AUC Score:\", roc_auc)\n",
    "# print(\"Mean Cross-Validation AUC:\", cv_scores.mean())\n",
    "# \n",
    "# # Generate the confusion matrix\n",
    "# conf_matrix_rf = confusion_matrix(Y_test, y_pred)\n",
    "# \n",
    "# # Extract TP, FP, FN, TN from the confusion matrix\n",
    "# TN_nn, FP_nn, FN_nn, TP_nn = conf_matrix_rf.ravel()\n",
    "# \n",
    "# # Print the TP/FP breakdown\n",
    "# print(f\"True Positives (TP): {TP_nn}\")\n",
    "# print(f\"False Positives (FP): {FP_nn}\")\n",
    "# print(f\"True Negatives (TN): {TN_nn}\")\n",
    "# print(f\"False Negatives (FN): {FN_nn}\")\n",
    "# \n",
    "# # Optionally, display the confusion matrix\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(conf_matrix_rf)\n",
    "# \n",
    "# auroc = roc_auc_score(Y_test, y_pred_proba)\n",
    "# print(f\"\\nAUROC: {auroc}\")\n",
    "# \n",
    "# # Plot the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(Y_test, y_pred_proba)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f\"AUROC = {auroc:.2f}\")\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ],
   "id": "922e7c5bcbb8ce4b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2) Gradient Boosting",
   "id": "68c287978d93b876"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.673843Z",
     "start_time": "2024-12-03T01:57:16.671704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import classification_report, roc_auc_score\n",
    "# from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# \n",
    "# # Step 1: Scale the Features (Gradient Boosting may not require scaling, but it can help in some cases)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# \n",
    "# # Step 2: Define the Gradient Boosting Classifier\n",
    "# xgb = XGBClassifier(\n",
    "#     n_estimators=100,          # Number of trees\n",
    "#     learning_rate=0.1,         # Step size for each iteration\n",
    "#     max_depth=3,               # Maximum tree depth\n",
    "#     subsample=0.8,             # Fraction of samples used for training each tree\n",
    "#     colsample_bytree=0.8,      # Fraction of features used for training each tree\n",
    "#     random_state=42            # For reproducibility\n",
    "# )\n",
    "# \n",
    "# # Step 3: Cross-Validation\n",
    "# cv_scores = cross_val_score(xgb, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "# \n",
    "# # Step 4: Train the Model\n",
    "# xgb.fit(X_train_scaled, y_train)\n",
    "# \n",
    "# # Step 5: Make Predictions\n",
    "# y_pred = xgb.predict(X_test_scaled)\n",
    "# y_pred_proba = xgb.predict_proba(X_test_scaled)[:, 1]\n",
    "# \n",
    "# # Step 6: Evaluate the Model\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "# print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "# print(\"Mean Cross-Validation AUC:\", cv_scores.mean())\n",
    "# \n",
    "# # Generate the confusion matrix\n",
    "# conf_matrix_gb = confusion_matrix(y_test, y_pred)\n",
    "# \n",
    "# # Extract TP, FP, FN, TN from the confusion matrix\n",
    "# TN_nn, FP_nn, FN_nn, TP_nn = conf_matrix_gb.ravel()\n",
    "# \n",
    "# # Print the TP/FP breakdown\n",
    "# print(f\"True Positives (TP): {TP_nn}\")\n",
    "# print(f\"False Positives (FP): {FP_nn}\")\n",
    "# print(f\"True Negatives (TN): {TN_nn}\")\n",
    "# print(f\"False Negatives (FN): {FN_nn}\")\n",
    "# \n",
    "# # Optionally, display the confusion matrix\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(conf_matrix_gb)\n",
    "# \n",
    "# auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "# print(f\"\\nAUROC: {auroc}\")\n",
    "# \n",
    "# # Plot the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f\"AUROC = {auroc:.2f}\")\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ],
   "id": "c4b1e4efaf721a80",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3 Neural Networks (Test)",
   "id": "4a533d3e6d2ea2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.711090Z",
     "start_time": "2024-12-03T01:57:16.708903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import classification_report, roc_auc_score\n",
    "# \n",
    "# # Step 1: Scale the Features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# \n",
    "# # Step 2: Build the Neural Network\n",
    "# model = Sequential([\n",
    "#     Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
    "#     Dropout(0.3),  # Add dropout for regularization\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
    "# ])\n",
    "# \n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# \n",
    "# # Step 3: Train the Model\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# \n",
    "# history = model.fit(\n",
    "#     X_train_scaled, y_train,\n",
    "#     validation_split=0.2,\n",
    "#     epochs=100,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[early_stopping],\n",
    "#     verbose=1\n",
    "# )\n",
    "# \n",
    "# # Step 4: Evaluate the Model\n",
    "# y_pred_proba_nn = model.predict(X_test_scaled)\n",
    "# y_pred_nn = (y_pred_proba_nn > 0.5).astype(int)\n",
    "# \n",
    "# # Performance Metrics\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nn))\n",
    "# print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba_nn))\n",
    "# \n",
    "# # Generate the confusion matrix\n",
    "# conf_matrix_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "# \n",
    "# # Extract TP, FP, FN, TN from the confusion matrix\n",
    "# TN_nn, FP_nn, FN_nn, TP_nn = conf_matrix_nn.ravel()\n",
    "# \n",
    "# # Print the TP/FP breakdown\n",
    "# print(f\"True Positives (TP): {TP_nn}\")\n",
    "# print(f\"False Positives (FP): {FP_nn}\")\n",
    "# print(f\"True Negatives (TN): {TN_nn}\")\n",
    "# print(f\"False Negatives (FN): {FN_nn}\")\n",
    "# \n",
    "# # Optionally, display the confusion matrix\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(conf_matrix_nn)\n",
    "# \n",
    "# auroc = roc_auc_score(y_test, y_pred_proba_nn)\n",
    "# print(f\"AUROC: {auroc}\")\n",
    "# \n",
    "# # Plot the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f\"AUROC = {auroc:.2f}\")\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ],
   "id": "a14d8611532717bc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.4) Ensemble Learning (Test)",
   "id": "b2929efd24673e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.747865Z",
     "start_time": "2024-12-03T01:57:16.745895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# # Example: Assuming X (features) and y (target) are already defined.\n",
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# \n",
    "# # Random Forest\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# rf_predictions = rf_model.predict(X_test)\n",
    "# rf_probabilities = rf_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "# \n",
    "# # Gradient Boosting\n",
    "# gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "# gb_model.fit(X_train, y_train)\n",
    "# gb_predictions = gb_model.predict(X_test)\n",
    "# gb_probabilities = gb_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "# \n",
    "# # Evaluate the models\n",
    "# rf_auroc = roc_auc_score(y_test, rf_probabilities)\n",
    "# gb_auroc = roc_auc_score(y_test, gb_probabilities)\n",
    "# \n",
    "# print(\"Random Forest AUROC:\", rf_auroc)\n",
    "# print(\"Gradient Boosting AUROC:\", gb_auroc)\n",
    "# \n",
    "# # Optional: Classification reports and accuracy\n",
    "# print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_predictions))\n",
    "# print(\"\\nGradient Boosting Classification Report:\\n\", classification_report(y_test, gb_predictions))\n",
    "# \n",
    "# # Plot the ROC curves\n",
    "# rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probabilities)\n",
    "# gb_fpr, gb_tpr, _ = roc_curve(y_test, gb_probabilities)\n",
    "# \n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(rf_fpr, rf_tpr, label=f\"Random Forest (AUROC = {rf_auroc:.2f})\")\n",
    "# plt.plot(gb_fpr, gb_tpr, label=f\"Gradient Boosting (AUROC = {gb_auroc:.2f})\")\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"ROC Curves\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# \n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# \n",
    "# # Compute confusion matrices for each model\n",
    "# rf_confusion = confusion_matrix(y_test, rf_predictions)\n",
    "# gb_confusion = confusion_matrix(y_test, gb_predictions)\n",
    "# \n",
    "# # Extract TP, TN, FP, FN for Random Forest\n",
    "# rf_tn, rf_fp, rf_fn, rf_tp = rf_confusion.ravel()\n",
    "# \n",
    "# # Extract TP, TN, FP, FN for Gradient Boosting\n",
    "# gb_tn, gb_fp, gb_fn, gb_tp = gb_confusion.ravel()\n",
    "# \n",
    "# # Display results\n",
    "# print(\"Random Forest Confusion Matrix:\")\n",
    "# print(rf_confusion)\n",
    "# print(f\"True Positives (TP): {rf_tp}\")\n",
    "# print(f\"True Negatives (TN): {rf_tn}\")\n",
    "# print(f\"False Positives (FP): {rf_fp}\")\n",
    "# print(f\"False Negatives (FN): {rf_fn}\\n\")\n",
    "# \n",
    "# print(\"Gradient Boosting Confusion Matrix:\")\n",
    "# print(gb_confusion)\n",
    "# print(f\"True Positives (TP): {gb_tp}\")\n",
    "# print(f\"True Negatives (TN): {gb_tn}\")\n",
    "# print(f\"False Positives (FP): {gb_fp}\")\n",
    "# print(f\"False Negatives (FN): {gb_fn}\")"
   ],
   "id": "d44d0690238b6f55",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.785184Z",
     "start_time": "2024-12-03T01:57:16.784079Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f8892472a539a7a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:57:16.823415Z",
     "start_time": "2024-12-03T01:57:16.822118Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "581973c07bcac384",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

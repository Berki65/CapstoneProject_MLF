{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning Project",
   "id": "1dd3de7524db47a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " 1) data curation: how you choose the features (X) and the target (Y)\n",
    " 2) exploratory data analysis (including visualization and correlation matrix)\n",
    " 3) univariate results (and meta analysis)\n",
    " 4) multivariate results (and meta analysis)\n",
    " 5) benchmark linear/logistic regressions (including higher-order polynomials and/or interaction terms)\n",
    " 6) one machine learning algorithm (e.g., random forests or boosting)\n",
    " 7) k-fold cross-validation \n",
    " 8) performance evaluation (R-squared, AUROC, etc.)\n",
    " 9) key features (dimension reduction and feature selection techniques if necessary)\n",
    " 10) synthetic interpretation of results"
   ],
   "id": "281e58ad36f26581"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "421a67cf0a25738"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:32.089072Z",
     "start_time": "2024-11-29T11:48:32.086497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from prompt_toolkit.key_binding.bindings.named_commands import yank_last_arg\n",
    "from sklearn.linear_model import LinearRegression"
   ],
   "id": "e7345ac4c349ce36",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and clear up dataset",
   "id": "b8e12046d0bf064b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1) Load and edit the Dataset",
   "id": "f3e554f4986dbb29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:32.143571Z",
     "start_time": "2024-11-29T11:48:32.096802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "dataset_train = pd.read_csv(\"PM_train.csv\")\n",
    "dataset_test = pd.read_csv(\"PM_test.csv\")\n",
    "\n",
    "# Shift the cycle column forward by 1 to identify the last cycle before it resets\n",
    "dataset_train['Y'] = (dataset_train['cycle'] == dataset_train.groupby('id')['cycle'].transform('max')).astype(int)\n",
    "dataset_test['Y'] = (dataset_test['cycle'] == dataset_test.groupby('id')['cycle'].transform('max')).astype(int)\n",
    "\n",
    "# Define selected columns, including 'Y'\n",
    "selected_columns = ['id', 'cycle', 'setting1', 'setting2', 's2', 's3', 's4', 's6', 's7', 's8', 's9', 's11', 's12', 's13', 's14', 's15', 's17', 's20', 's21', 'Y']\n",
    "\n",
    "# Select the subset of data\n",
    "selected_dataset_train = dataset_train[selected_columns]\n",
    "selected_dataset_test = dataset_test[selected_columns]\n",
    "\n",
    "## Save the selected dataset to an Excel file\n",
    "# selected_dataset.to_excel(\"selected_dataset_with_Y.xlsx\", index=False)\n",
    "\n",
    "# Sort by 'id' and 'cycle' to ensure the data is in the correct order\n",
    "dataset_train = dataset_train.sort_values(['id', 'cycle'])\n",
    "dataset_test = dataset_test.sort_values(['id', 'cycle'])\n",
    "\n",
    "# Group by 'id' and select the last 10 cycles for each 'id'\n",
    "last_10_cycles_train = dataset_train.groupby('id').tail(10)\n",
    "last_10_cycles_test = dataset_test.groupby('id').tail(10)\n",
    "\n",
    "# Further filter the selected columns for this subset\n",
    "selected_last_10_cycles_train = last_10_cycles_train[selected_columns]\n",
    "selected_last_10_cycles_test = last_10_cycles_test[selected_columns]\n",
    "\n",
    "# Display the result\n",
    "selected_last_10_cycles_train.head()\n",
    "selected_last_10_cycles_test.head()\n",
    "\n",
    "# Define the features (X) and target (Y)\n",
    "X_train = selected_dataset_train # .drop(columns=['Y', 'id', 'cycle'])  # Drop 'Y', 'id', and 'cycle' if they are not part of the model\n",
    "Y_train = selected_dataset_train['Y']\n",
    "X_test = selected_dataset_test #.drop(columns=['Y', 'id', 'cycle'])  # Drop 'Y', 'id', and 'cycle' if they are not part of the model\n",
    "Y_test = selected_dataset_test['Y']\n",
    "\n",
    "# Alternatively, if using only the last 10 cycles:\n",
    "X_last_10_train = selected_last_10_cycles_train.drop(columns=['Y', 'id', 'cycle'])\n",
    "Y_last_10_train = selected_last_10_cycles_train['Y']\n",
    "X_last_10_test = selected_last_10_cycles_test.drop(columns=['Y', 'id', 'cycle'])\n",
    "Y_last_10_test = selected_last_10_cycles_test['Y']\n"
   ],
   "id": "f3fdc0d7b157bc90",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1) Visualization of the whole Dataset",
   "id": "4e9e1e485e4cff15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:32.191122Z",
     "start_time": "2024-11-29T11:48:32.189259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Visualization \n",
    "# selected_dataset_train.head()\n",
    "# selected_dataset_train.info()\n",
    "# \n",
    "# for column in selected_dataset_train.columns:\n",
    "#     if column not in ['id', 'Y']:  # Skip 'id' and 'Y' for this general visualization\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.title(f\"Distribution of {column}\")\n",
    "#         plt.plot(selected_dataset_train['cycle'], selected_dataset_train[column], alpha=0.7)\n",
    "#         plt.xlabel(\"Cycle\")\n",
    "#         plt.ylabel(column)\n",
    "#         plt.grid(True, alpha=0.5)\n",
    "#         plt.show()\n"
   ],
   "id": "d039a8b50c7b8c5f",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2) Visualization of the last 10 cycles",
   "id": "a8748228ffa8eea3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:32.237547Z",
     "start_time": "2024-11-29T11:48:32.235991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# selected_last_10_cycles_train.head()\n",
    "# selected_last_10_cycles_train.info()\n",
    "# \n",
    "# for column in selected_last_10_cycles_train.columns:\n",
    "#     if column not in ['id', 'Y']:  # Skip 'id' and 'Y' for this general visualization\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.title(f\"Distribution of {column}\")\n",
    "#         plt.plot(selected_last_10_cycles_train['cycle'], selected_last_10_cycles_train[column], alpha=0.7)\n",
    "#         plt.xlabel(\"Cycle\")\n",
    "#         plt.ylabel(column)\n",
    "#         plt.grid(True, alpha=0.5)\n",
    "#         plt.show()"
   ],
   "id": "87c96e24a1f91e01",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3) Scatter Plot Matrix",
   "id": "443f6e62111be658"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:32.284172Z",
     "start_time": "2024-11-29T11:48:32.282274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Heatmap\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# correlation_matrix = selected_last_10_cycles_train.corr()  # Compute the correlation matrix\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "# plt.title('Correlation Matrix Heatmap (Last 10 Cycles)')\n",
    "# plt.show()\n",
    "# \n",
    "# # Scatter plot matrix\n",
    "# numeric_columns = [col for col in selected_columns if col not in ['id', 'Y', 'cycle']]\n",
    "# sns.pairplot(selected_last_10_cycles_train, vars=numeric_columns[:20])  # Limit to first 6 for clarity\n",
    "# plt.suptitle('Scatter Plot Matrix (Last 10 Cycles)', y=1.02)\n",
    "# plt.show()\n",
    "# \n",
    "# # 3D Scatter Plot\n",
    "# fig = plt.figure(figsize=(10, 7))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(\n",
    "#     selected_last_10_cycles_train['setting1'],\n",
    "#     selected_last_10_cycles_train['s2'],\n",
    "#     selected_last_10_cycles_train['s3'],\n",
    "#     c='b', marker='o'\n",
    "# )\n",
    "# \n",
    "# # Label the axes\n",
    "# ax.set_xlabel('Setting 1')\n",
    "# ax.set_ylabel('S2')\n",
    "# ax.set_zlabel('S3')\n",
    "# plt.title('3D Scatter Plot (Last 10 Cycles)')\n",
    "# plt.show()"
   ],
   "id": "1af116a0148278c0",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Regression",
   "id": "fa1dcc68789bc81e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:32.350157Z",
     "start_time": "2024-11-29T11:48:32.327454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit the regression model\n",
    "model = LinearRegression()\n",
    "# model.fit(X_train, Y_train)\n",
    "model.fit(X_last_10_train, Y_last_10_train)\n",
    "\n",
    "# Define the threshold for binary classification\n",
    "threshold = 2\n",
    "\n",
    "# Predict using the regression model\n",
    "y_pred = model.predict(X_last_10_test)\n",
    "\n",
    "# Convert regression outputs and true labels to binary\n",
    "y_test_binary = selected_last_10_cycles_test['Y']\n",
    "y_pred_binary = (y_pred <= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test_binary, y_pred_binary))"
   ],
   "id": "e10320cbbe9288",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       828\n",
      "           1       0.10      1.00      0.18        92\n",
      "\n",
      "    accuracy                           0.10       920\n",
      "   macro avg       0.05      0.50      0.09       920\n",
      "weighted avg       0.01      0.10      0.02       920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/Project/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:32.473433Z",
     "start_time": "2024-11-29T11:48:32.468877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_columns = [col for col in selected_columns if col not in ['id', 'cycle', 'Y']]\n",
    "# \n",
    "# # Create scatter plots with regression lines\n",
    "# for column in x_columns:\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     sns.regplot(x=selected_last_10_cycles[column], y=selected_last_10_cycles['Y'], scatter_kws={'s': 10}, line_kws={'color': 'red'})\n",
    "#     plt.title(f'Regression of Y on {column}')\n",
    "#     plt.xlabel(column)\n",
    "#     plt.ylabel('Y')\n",
    "#     plt.show()"
   ],
   "id": "1074f5c2f2db0662",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "fdfd919f873e5413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:40.702491Z",
     "start_time": "2024-11-29T11:48:32.558021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Step 1: Create target labels indicating engine swap (1: needs swapping, 0: does not need swapping)\n",
    "threshold = 10  # Define the threshold for remaining cycles\n",
    "train_data['RUL'] = train_data.groupby('id')['cycle'].transform(max) - train_data['cycle']\n",
    "train_data['Y'] = (train_data['RUL'] <= threshold).astype(int)\n",
    "\n",
    "# Step 2: Define features (X) and target (Y)\n",
    "features = train_data.columns.difference(['id', 'cycle', 'RUL', 'Y'])\n",
    "X = train_data[features]\n",
    "y = train_data['Y']\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Random Forest Classifier with Cross-Validation\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Performance Metrics\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print results\n",
    "print(\"Classification Report:\\n\", classification_report_result)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "print(\"Mean Cross-Validation AUC:\", cv_scores.mean())\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract TP, FP, FN, TN from the confusion matrix\n",
    "TN_nn, FP_nn, FN_nn, TP_nn = conf_matrix_nn.ravel()\n",
    "\n",
    "# Print the TP/FP breakdown\n",
    "print(f\"True Positives (TP): {TP_nn}\")\n",
    "print(f\"False Positives (FP): {FP_nn}\")\n",
    "print(f\"True Negatives (TN): {TN_nn}\")\n",
    "print(f\"False Negatives (FN): {FN_nn}\")\n",
    "\n",
    "# Optionally, display the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_rf)"
   ],
   "id": "922e7c5bcbb8ce4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3918\n",
      "           1       0.87      0.82      0.84       209\n",
      "\n",
      "    accuracy                           0.98      4127\n",
      "   macro avg       0.93      0.91      0.92      4127\n",
      "weighted avg       0.98      0.98      0.98      4127\n",
      "\n",
      "ROC-AUC Score: 0.9958075963959738\n",
      "Mean Cross-Validation AUC: 0.9929789733679174\n",
      "True Positives (TP): 184\n",
      "False Positives (FP): 36\n",
      "True Negatives (TN): 3882\n",
      "False Negatives (FN): 25\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3893   25]\n",
      " [  38  171]]\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradient Boosting",
   "id": "68c287978d93b876"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:41.089720Z",
     "start_time": "2024-11-29T11:48:40.748448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Scale the Features (Gradient Boosting may not require scaling, but it can help in some cases)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Define the Gradient Boosting Classifier\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,          # Number of trees\n",
    "    learning_rate=0.1,         # Step size for each iteration\n",
    "    max_depth=3,               # Maximum tree depth\n",
    "    subsample=0.8,             # Fraction of samples used for training each tree\n",
    "    colsample_bytree=0.8,      # Fraction of features used for training each tree\n",
    "    random_state=42            # For reproducibility\n",
    ")\n",
    "\n",
    "# Step 3: Cross-Validation\n",
    "cv_scores = cross_val_score(xgb, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Step 4: Train the Model\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Make Predictions\n",
    "y_pred = xgb.predict(X_test_scaled)\n",
    "y_pred_proba = xgb.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"Mean Cross-Validation AUC:\", cv_scores.mean())\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix_gb = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract TP, FP, FN, TN from the confusion matrix\n",
    "TN_nn, FP_nn, FN_nn, TP_nn = conf_matrix_gb.ravel()\n",
    "\n",
    "# Print the TP/FP breakdown\n",
    "print(f\"True Positives (TP): {TP_nn}\")\n",
    "print(f\"False Positives (FP): {FP_nn}\")\n",
    "print(f\"True Negatives (TN): {TN_nn}\")\n",
    "print(f\"False Negatives (FN): {FN_nn}\")\n",
    "\n",
    "# Optionally, display the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_gb)"
   ],
   "id": "c4b1e4efaf721a80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3918\n",
      "           1       0.85      0.84      0.85       209\n",
      "\n",
      "    accuracy                           0.98      4127\n",
      "   macro avg       0.92      0.91      0.92      4127\n",
      "weighted avg       0.98      0.98      0.98      4127\n",
      "\n",
      "ROC-AUC Score: 0.9958649931246046\n",
      "Mean Cross-Validation AUC: 0.9943795561560238\n",
      "True Positives (TP): 175\n",
      "False Positives (FP): 30\n",
      "True Negatives (TN): 3888\n",
      "False Negatives (FN): 34\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3888   30]\n",
      " [  34  175]]\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Neural Networks",
   "id": "4a533d3e6d2ea2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:48.748679Z",
     "start_time": "2024-11-29T11:48:41.138749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Step 1: Scale the Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Build the Neural Network\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
    "    Dropout(0.3),  # Add dropout for regularization\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 3: Train the Model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "y_pred_proba_nn = model.predict(X_test_scaled)\n",
    "y_pred_nn = (y_pred_proba_nn > 0.5).astype(int)\n",
    "\n",
    "# Performance Metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nn))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba_nn))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "\n",
    "# Extract TP, FP, FN, TN from the confusion matrix\n",
    "TN_nn, FP_nn, FN_nn, TP_nn = conf_matrix_nn.ravel()\n",
    "\n",
    "# Print the TP/FP breakdown\n",
    "print(f\"True Positives (TP): {TP_nn}\")\n",
    "print(f\"False Positives (FP): {FP_nn}\")\n",
    "print(f\"True Negatives (TN): {TN_nn}\")\n",
    "print(f\"False Negatives (FN): {FN_nn}\")\n",
    "\n",
    "# Optionally, display the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_nn)\n"
   ],
   "id": "a14d8611532717bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "413/413 [==============================] - 0s 668us/step - loss: 0.1626 - accuracy: 0.9469 - val_loss: 0.0844 - val_accuracy: 0.9652\n",
      "Epoch 2/100\n",
      "413/413 [==============================] - 0s 549us/step - loss: 0.0825 - accuracy: 0.9651 - val_loss: 0.0688 - val_accuracy: 0.9673\n",
      "Epoch 3/100\n",
      "413/413 [==============================] - 0s 552us/step - loss: 0.0720 - accuracy: 0.9667 - val_loss: 0.0641 - val_accuracy: 0.9700\n",
      "Epoch 4/100\n",
      "413/413 [==============================] - 0s 547us/step - loss: 0.0639 - accuracy: 0.9702 - val_loss: 0.0602 - val_accuracy: 0.9703\n",
      "Epoch 5/100\n",
      "413/413 [==============================] - 0s 543us/step - loss: 0.0597 - accuracy: 0.9737 - val_loss: 0.0575 - val_accuracy: 0.9739\n",
      "Epoch 6/100\n",
      "413/413 [==============================] - 0s 580us/step - loss: 0.0574 - accuracy: 0.9737 - val_loss: 0.0580 - val_accuracy: 0.9730\n",
      "Epoch 7/100\n",
      "413/413 [==============================] - 0s 568us/step - loss: 0.0561 - accuracy: 0.9753 - val_loss: 0.0546 - val_accuracy: 0.9749\n",
      "Epoch 8/100\n",
      "413/413 [==============================] - 0s 565us/step - loss: 0.0522 - accuracy: 0.9773 - val_loss: 0.0604 - val_accuracy: 0.9703\n",
      "Epoch 9/100\n",
      "413/413 [==============================] - 0s 572us/step - loss: 0.0532 - accuracy: 0.9761 - val_loss: 0.0535 - val_accuracy: 0.9733\n",
      "Epoch 10/100\n",
      "413/413 [==============================] - 0s 559us/step - loss: 0.0510 - accuracy: 0.9758 - val_loss: 0.0546 - val_accuracy: 0.9755\n",
      "Epoch 11/100\n",
      "413/413 [==============================] - 0s 542us/step - loss: 0.0515 - accuracy: 0.9775 - val_loss: 0.0518 - val_accuracy: 0.9770\n",
      "Epoch 12/100\n",
      "413/413 [==============================] - 0s 538us/step - loss: 0.0506 - accuracy: 0.9777 - val_loss: 0.0518 - val_accuracy: 0.9752\n",
      "Epoch 13/100\n",
      "413/413 [==============================] - 0s 531us/step - loss: 0.0509 - accuracy: 0.9769 - val_loss: 0.0544 - val_accuracy: 0.9746\n",
      "Epoch 14/100\n",
      "413/413 [==============================] - 0s 538us/step - loss: 0.0487 - accuracy: 0.9783 - val_loss: 0.0530 - val_accuracy: 0.9761\n",
      "Epoch 15/100\n",
      "413/413 [==============================] - 0s 535us/step - loss: 0.0470 - accuracy: 0.9796 - val_loss: 0.0569 - val_accuracy: 0.9736\n",
      "Epoch 16/100\n",
      "413/413 [==============================] - 0s 573us/step - loss: 0.0478 - accuracy: 0.9796 - val_loss: 0.0512 - val_accuracy: 0.9755\n",
      "Epoch 17/100\n",
      "413/413 [==============================] - 0s 535us/step - loss: 0.0465 - accuracy: 0.9787 - val_loss: 0.0511 - val_accuracy: 0.9776\n",
      "Epoch 18/100\n",
      "413/413 [==============================] - 0s 534us/step - loss: 0.0467 - accuracy: 0.9789 - val_loss: 0.0515 - val_accuracy: 0.9761\n",
      "Epoch 19/100\n",
      "413/413 [==============================] - 0s 545us/step - loss: 0.0463 - accuracy: 0.9802 - val_loss: 0.0541 - val_accuracy: 0.9779\n",
      "Epoch 20/100\n",
      "413/413 [==============================] - 0s 540us/step - loss: 0.0449 - accuracy: 0.9808 - val_loss: 0.0515 - val_accuracy: 0.9755\n",
      "Epoch 21/100\n",
      "413/413 [==============================] - 0s 574us/step - loss: 0.0441 - accuracy: 0.9805 - val_loss: 0.0513 - val_accuracy: 0.9761\n",
      "Epoch 22/100\n",
      "413/413 [==============================] - 0s 574us/step - loss: 0.0445 - accuracy: 0.9811 - val_loss: 0.0489 - val_accuracy: 0.9770\n",
      "Epoch 23/100\n",
      "413/413 [==============================] - 0s 561us/step - loss: 0.0435 - accuracy: 0.9806 - val_loss: 0.0546 - val_accuracy: 0.9739\n",
      "Epoch 24/100\n",
      "413/413 [==============================] - 0s 544us/step - loss: 0.0443 - accuracy: 0.9800 - val_loss: 0.0547 - val_accuracy: 0.9767\n",
      "Epoch 25/100\n",
      "413/413 [==============================] - 0s 528us/step - loss: 0.0429 - accuracy: 0.9799 - val_loss: 0.0508 - val_accuracy: 0.9770\n",
      "Epoch 26/100\n",
      "413/413 [==============================] - 0s 535us/step - loss: 0.0444 - accuracy: 0.9811 - val_loss: 0.0498 - val_accuracy: 0.9767\n",
      "Epoch 27/100\n",
      "413/413 [==============================] - 0s 538us/step - loss: 0.0424 - accuracy: 0.9815 - val_loss: 0.0518 - val_accuracy: 0.9755\n",
      "Epoch 28/100\n",
      "413/413 [==============================] - 0s 569us/step - loss: 0.0446 - accuracy: 0.9808 - val_loss: 0.0542 - val_accuracy: 0.9785\n",
      "Epoch 29/100\n",
      "413/413 [==============================] - 0s 582us/step - loss: 0.0432 - accuracy: 0.9816 - val_loss: 0.0534 - val_accuracy: 0.9779\n",
      "Epoch 30/100\n",
      "413/413 [==============================] - 0s 543us/step - loss: 0.0430 - accuracy: 0.9812 - val_loss: 0.0515 - val_accuracy: 0.9761\n",
      "Epoch 31/100\n",
      "413/413 [==============================] - 0s 572us/step - loss: 0.0425 - accuracy: 0.9814 - val_loss: 0.0513 - val_accuracy: 0.9779\n",
      "Epoch 32/100\n",
      "413/413 [==============================] - 0s 545us/step - loss: 0.0408 - accuracy: 0.9813 - val_loss: 0.0513 - val_accuracy: 0.9746\n",
      "129/129 [==============================] - 0s 202us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3918\n",
      "           1       0.84      0.89      0.86       209\n",
      "\n",
      "    accuracy                           0.99      4127\n",
      "   macro avg       0.92      0.94      0.93      4127\n",
      "weighted avg       0.99      0.99      0.99      4127\n",
      "\n",
      "ROC-AUC Score: 0.9962399036711924\n",
      "True Positives (TP): 185\n",
      "False Positives (FP): 34\n",
      "True Negatives (TN): 3884\n",
      "False Negatives (FN): 24\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3884   34]\n",
      " [  24  185]]\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:48:48.795654Z",
     "start_time": "2024-11-29T11:48:48.794233Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d44d0690238b6f55",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
